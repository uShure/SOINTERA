import fs from 'fs';
import path from 'path';
import { exec, execSync as cpExecSync } from 'child_process';
import { promisify } from 'util';
import ffmpeg from 'fluent-ffmpeg';

const execAsync = promisify(exec);

/**
 * üé§ –ë–ï–°–ü–õ–ê–¢–ù–´–ô –≥–æ–ª–æ—Å–æ–≤–æ–π —Å–µ—Ä–≤–∏—Å SOINTERA AI
 * 
 * –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
 * - eSpeak-ng –¥–ª—è Text-to-Speech (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
 * - Whisper –¥–ª—è Speech-to-Text (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
 * - FFmpeg –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ
 * 
 * –ù–ï —Ç—Ä–µ–±—É–µ—Ç –ø–ª–∞—Ç–Ω—ã—Ö API –∫–ª—é—á–µ–π!
 */
export class FreeVoiceService {
  private tempDir: string;
  private espeakPath: string;
  private whisperPath: string;

  constructor() {
    // –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
    this.tempDir = path.join(process.cwd(), 'temp', 'voice');
    if (!fs.existsSync(this.tempDir)) {
      fs.mkdirSync(this.tempDir, { recursive: true });
    }

    // –ü—É—Ç–∏ –∫ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º —Ñ–∞–π–ª–∞–º
    this.espeakPath = this.findEspeakPath();
    this.whisperPath = this.findWhisperPath();
  }

  /**
   * üîç –ü–æ–∏—Å–∫ –ø—É—Ç–∏ –∫ eSpeak
   */
  private findEspeakPath(): string {
    // 1) Env override
    const envEspeak = process.env.ESPEAK_PATH || process.env.ESPEAK_NG_PATH;
    if (envEspeak) {
      try {
        cpExecSync(`"${envEspeak}" --version`, { stdio: 'ignore' });
        return envEspeak;
      } catch {}
    }

    // 2) Use shell resolution if available
    try {
      const resolved = cpExecSync('command -v espeak-ng', { encoding: 'utf8' }).toString().trim();
      if (resolved) {
        return resolved;
      }
    } catch {}

    const possiblePaths = [
      'espeak-ng',
      'espeak',
      '/usr/bin/espeak-ng',
      '/bin/espeak-ng',
      '/usr/local/bin/espeak-ng',
      'C:\\Program Files\\eSpeak\\espeak.exe',
      'C:\\Program Files (x86)\\eSpeak\\espeak.exe'
    ];

    for (const path of possiblePaths) {
      try {
        console.log(`üîç –ü—Ä–æ–≤–µ—Ä—è—é –ø—É—Ç—å: ${path}`);
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        cpExecSync(`"${path}" --version`, { stdio: 'ignore' });
        console.log(`‚úÖ –ù–∞–π–¥–µ–Ω eSpeak: ${path}`);
        return path;
      } catch (error) {
        console.log(`‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω: ${path}`);
        continue;
      }
    }

    throw new Error('eSpeak –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ eSpeak-ng –¥–ª—è TTS —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.');
  }

  /**
   * üîç –ü–æ–∏—Å–∫ –ø—É—Ç–∏ –∫ Whisper
   */
  private findWhisperPath(): string {
    // 1) Env override
    const envWhisper = process.env.WHISPER_PATH;
    if (envWhisper) {
      try {
        cpExecSync(`"${envWhisper}" --version`, { stdio: 'ignore' });
        return envWhisper;
      } catch {}
    }

    // 2) Use shell resolution if available
    try {
      const resolved = cpExecSync('command -v whisper', { encoding: 'utf8' }).toString().trim();
      if (resolved) {
        return resolved;
      }
    } catch {}

    const possiblePaths = [
      'whisper',
      'whisper-ai',
      '/opt/whisper-venv/bin/whisper',
      '/usr/local/bin/whisper',
      'C:\\Users\\%USERNAME%\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\whisper.exe'
    ];

    for (const path of possiblePaths) {
      try {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        // –£ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–±–æ—Ä–æ–∫ whisper –Ω–µ—Ç –∫–ª—é—á–∞ --version, –∏—Å–ø–æ–ª—å–∑—É–µ–º --help
        cpExecSync(`"${path}" --help`, { stdio: 'ignore' });
        return path;
      } catch {
        continue;
      }
    }

    throw new Error('Whisper –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Whisper –¥–ª—è STT —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.');
  }

  /**
   * üó£Ô∏è Text-to-Speech —Å eSpeak (–ë–ï–°–ü–õ–ê–¢–ù–û)
   */
  async textToSpeech(text: string, options: {
    voice?: string;
    language?: string;
    speed?: number;
    pitch?: number;
    volume?: number;
  } = {}): Promise<Buffer> {
    try {
      const {
        voice = 'ru',
        language = 'ru',
        speed = 150, // —Å–ª–æ–≤–∞ –≤ –º–∏–Ω—É—Ç—É
        pitch = 50,  // 0-100
        volume = 100 // 0-100
      } = options;

      const outputFile = path.join(this.tempDir, `tts_${Date.now()}.wav`);
      
      // –ö–æ–º–∞–Ω–¥–∞ eSpeak —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
      const command = `"${this.espeakPath}" -v ${voice} -s ${speed} -p ${pitch} -a ${volume} -w "${outputFile}" "${text}"`;
      
      await execAsync(command);
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
      if (!fs.existsSync(outputFile)) {
        throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª');
      }

      // –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –≤ –±—É—Ñ–µ—Ä
      const audioBuffer = fs.readFileSync(outputFile);
      
      // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
      fs.unlinkSync(outputFile);
      
      return audioBuffer;
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ TTS (eSpeak):', error);
      throw error;
    }
  }

  /**
   * üéß Speech-to-Text —Å Whisper (–ë–ï–°–ü–õ–ê–¢–ù–û)
   */
  async speechToText(audioBuffer: Buffer, options: {
    language?: string;
    model?: string;
  } = {}): Promise<string> {
    try {
      const {
        language = 'ru',
        model = 'base' // tiny, base, small, medium, large
      } = options;

      const inputFile = path.join(this.tempDir, `stt_input_${Date.now()}.wav`);
      const outputFile = path.join(this.tempDir, `stt_output_${Date.now()}.txt`);
      
      // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
      fs.writeFileSync(inputFile, audioBuffer);
      
      // –ö–æ–º–∞–Ω–¥–∞ Whisper
      const command = `"${this.whisperPath}" "${inputFile}" --language ${language} --model ${model} --output_dir "${this.tempDir}" --output_format txt`;
      
      await execAsync(command);
      
      // –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      let transcript = '';
      if (fs.existsSync(outputFile)) {
        transcript = fs.readFileSync(outputFile, 'utf-8').trim();
      }
      
      // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
      try {
        fs.unlinkSync(inputFile);
        if (fs.existsSync(outputFile)) {
          fs.unlinkSync(outputFile);
        }
      } catch {}
      
      return transcript || '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å';
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ STT (Whisper):', error);
      throw error;
    }
  }

  /**
   * üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
   */
  async convertAudio(inputBuffer: Buffer, outputFormat: 'mp3' | 'ogg' | 'wav' = 'mp3'): Promise<Buffer> {
    return new Promise((resolve, reject) => {
      const inputPath = path.join(this.tempDir, `input_${Date.now()}.tmp`);
      const outputPath = path.join(this.tempDir, `output_${Date.now()}.${outputFormat}`);

      // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ö–æ–¥–Ω–æ–π –±—É—Ñ–µ—Ä –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
      fs.writeFileSync(inputPath, inputBuffer);

      ffmpeg(inputPath)
        .toFormat(outputFormat)
        .audioChannels(1)
        .audioFrequency(16000)
        .audioBitrate('64k')
        .on('end', () => {
          try {
            const outputBuffer = fs.readFileSync(outputPath);
            
            // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            fs.unlinkSync(inputPath);
            fs.unlinkSync(outputPath);
            
            resolve(outputBuffer);
          } catch (error) {
            reject(error);
          }
        })
        .on('error', (error) => {
          // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ –æ—à–∏–±–∫–µ
          try {
            if (fs.existsSync(inputPath)) fs.unlinkSync(inputPath);
            if (fs.existsSync(outputPath)) fs.unlinkSync(outputPath);
          } catch {}
          
          reject(error);
        })
        .save(outputPath);
    });
  }

  /**
   * üéµ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ –¥–ª—è Telegram
   */
  async optimizeForTelegram(audioBuffer: Buffer): Promise<Buffer> {
    return new Promise((resolve, reject) => {
      const inputPath = path.join(this.tempDir, `input_${Date.now()}.tmp`);
      const outputPath = path.join(this.tempDir, `optimized_${Date.now()}.mp3`);

      fs.writeFileSync(inputPath, audioBuffer);

      ffmpeg(inputPath)
        .toFormat('mp3')
        .audioChannels(1)
        .audioFrequency(22050)
        .audioBitrate('48k')
        .audioCodec('libmp3lame')
        .audioFilters([
          'highpass=f=200',
          'lowpass=f=8000',
          'volume=1.2'
        ])
        .on('end', () => {
          try {
            const outputBuffer = fs.readFileSync(outputPath);
            
            // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            fs.unlinkSync(inputPath);
            fs.unlinkSync(outputPath);
            
            resolve(outputBuffer);
          } catch (error) {
            reject(error);
          }
        })
        .on('error', (error) => {
          try {
            if (fs.existsSync(inputPath)) fs.unlinkSync(inputPath);
            if (fs.existsSync(outputPath)) fs.unlinkSync(outputPath);
          } catch {}
          
          reject(error);
        })
        .save(outputPath);
    });
  }

  /**
   * üé≠ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–∞ —Å —ç–º–æ—Ü–∏—è–º–∏
   */
  async generateEmotionalVoice(text: string, emotion: 'friendly' | 'professional' | 'enthusiastic' | 'calm'): Promise<Buffer> {
    const voiceSettings = this.getVoiceSettingsForEmotion(emotion);
    return await this.textToSpeech(text, voiceSettings);
  }

  /**
   * üé≠ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ–ª–æ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–º–æ—Ü–∏–π
   */
  private getVoiceSettingsForEmotion(emotion: string): {
    voice: string;
    language: string;
    speed: number;
    pitch: number;
    volume: number;
  } {
    const baseSettings = {
      voice: 'ru',
      language: 'ru'
    };

    switch (emotion) {
      case 'friendly':
        return { ...baseSettings, speed: 140, pitch: 55, volume: 100 };
      case 'professional':
        return { ...baseSettings, speed: 160, pitch: 45, volume: 95 };
      case 'enthusiastic':
        return { ...baseSettings, speed: 170, pitch: 60, volume: 110 };
      case 'calm':
        return { ...baseSettings, speed: 130, pitch: 40, volume: 90 };
      default:
        return { ...baseSettings, speed: 150, pitch: 50, volume: 100 };
    }
  }

  /**
   * üë• –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ–ª–æ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤
   */
  async generateCustomerVoice(text: string, customerType: 'beginner' | 'experienced' | 'interested' | 'ready_to_buy'): Promise<Buffer> {
    const voiceSettings = this.getVoiceSettingsForCustomer(customerType);
    return await this.textToSpeech(text, voiceSettings);
  }

  /**
   * üë• –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ–ª–æ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤
   */
  private getVoiceSettingsForCustomer(customerType: string): {
    voice: string;
    language: string;
    speed: number;
    pitch: number;
    volume: number;
  } {
    const baseSettings = {
      voice: 'ru',
      language: 'ru'
    };

    switch (customerType) {
      case 'beginner':
        return { ...baseSettings, speed: 130, pitch: 45, volume: 105 }; // –ú–µ–¥–ª–µ–Ω–Ω–µ–µ, –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–µ–µ
      case 'experienced':
        return { ...baseSettings, speed: 170, pitch: 55, volume: 100 }; // –ë—ã—Å—Ç—Ä–µ–µ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–µ–µ
      case 'interested':
        return { ...baseSettings, speed: 150, pitch: 50, volume: 100 }; // –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ
      case 'ready_to_buy':
        return { ...baseSettings, speed: 160, pitch: 60, volume: 110 }; // –≠–Ω–µ—Ä–≥–∏—á–Ω–æ, —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ
      default:
        return { ...baseSettings, speed: 150, pitch: 50, volume: 100 };
    }
  }

  /**
   * üé§ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤ eSpeak
   */
  async getAvailableVoices(): Promise<string[]> {
    try {
      const { stdout } = await execAsync(`"${this.espeakPath}" --voices`);
      
      return stdout
        .split('\n')
        .filter(line => line.trim() && line.includes('ru'))
        .map(line => {
          const parts = line.split(/\s+/);
          return parts[1] || 'ru'; // –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ —è–∑—ã–∫–∞
        })
        .filter((voice, index, arr) => arr.indexOf(voice) === index); // –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤ eSpeak:', error);
      return ['ru']; // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å
    }
  }

  /**
   * üìä –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
   */
  getStats(): {
    tempDir: string;
    tempFilesCount: number;
    espeakPath: string;
    whisperPath: string;
  } {
    try {
      const files = fs.readdirSync(this.tempDir);
      return {
        tempDir: this.tempDir,
        tempFilesCount: files.length,
        espeakPath: this.espeakPath,
        whisperPath: this.whisperPath
      };
    } catch (error) {
      return {
        tempDir: this.tempDir,
        tempFilesCount: 0,
        espeakPath: this.espeakPath,
        whisperPath: this.whisperPath
      };
    }
  }

  /**
   * üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
   */
  async cleanup(): Promise<void> {
    try {
      const files = fs.readdirSync(this.tempDir);
      for (const file of files) {
        const filePath = path.join(this.tempDir, file);
        if (fs.statSync(filePath).isFile()) {
          fs.unlinkSync(filePath);
        }
      }
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:', error);
    }
  }

  /**
   * ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤
   */
  async checkAvailability(): Promise<{
    espeak: boolean;
    whisper: boolean;
    ffmpeg: boolean;
  }> {
    const result = {
      espeak: false,
      whisper: false,
      ffmpeg: false
    };

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º eSpeak
      await execAsync(`"${this.espeakPath}" --version`);
      result.espeak = true;
    } catch {
      result.espeak = false;
    }

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º Whisper (–∏—Å–ø–æ–ª—å–∑—É–µ–º --help –≤–º–µ—Å—Ç–æ --version)
      await execAsync(`"${this.whisperPath}" --help`);
      result.whisper = true;
    } catch {
      result.whisper = false;
    }

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º FFmpeg
      await execAsync('ffmpeg -version');
      result.ffmpeg = true;
    } catch {
      result.ffmpeg = false;
    }

    return result;
  }

  /**
   * üìÅ –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —á–µ—Ä–µ–∑ Bot API
   */
  async createTempAudioFile(audioBuffer: Buffer, filename?: string): Promise<string> {
    const tempFileName = filename || `voice_${Date.now()}.wav`;
    const tempFilePath = path.join(this.tempDir, tempFileName);
    
    try {
      fs.writeFileSync(tempFilePath, audioBuffer);
      return tempFilePath;
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞:', error);
      throw error;
    }
  }

  /**
   * üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
   */
  async removeTempAudioFile(filePath: string): Promise<void> {
    try {
      if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
      }
    } catch (error) {
      console.error('–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞:', error);
    }
  }
}

// –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è execSync
function execSync(command: string, options: any): void {
  const { execSync: execSyncFn } = require('child_process');
  execSyncFn(command, options);
}
